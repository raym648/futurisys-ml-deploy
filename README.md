# Futurisys ‚Äì D√©ploiement d‚Äôun Mod√®le de Machine Learning (futurisys-ml-deploy)

**Projet-5 - D√©ployez un mod√®le de Machine Learning**

**‚úçÔ∏è Auteur :** *[Raymond Francius]* 
**üìö R√¥le :** *[Apprenant - Promotion Sept-2025]* ‚Äî **Engineer AI** ‚Äî **Openclassrooms**  
üóìÔ∏è **Date de mise √† jour :** *[18-12-2025]*


## üìå Pr√©sentation du projet

Ce projet s‚Äôinscrit dans le **Projet‚Äë5 ‚Äì D√©ployez un mod√®le de Machine Learning**. Il vise √† exposer un mod√®le de classification via une API FastAPI, √† assurer la tra√ßabilit√© compl√®te des donn√©es et des pr√©dictions dans PostgreSQL (Neon serverless), et √† fournir un dashboard de visualisation d√©ploy√© sur Hugging Face Spaces.

Le projet adopte une approche **MLOps** : versionnement des artefacts, tests automatis√©s, CI/CD, monitoring et documentation.

---

## üß† Mod√®le de Machine Learning

* **Type** : Classification binaire
* **Mod√®le par d√©faut** : `random_forest_e04`
* **Pipeline** : SMOTE + RandomForest
* **Artefacts** : `.joblib`, `.npy`, `.csv`
* **Frameworks** : scikit‚Äëlearn, numpy

Le mod√®le est charg√© dynamiquement sans r√©‚Äëentra√Ænement lors du d√©ploiement.

---

## üöÄ API FastAPI

L‚ÄôAPI expose plusieurs endpoints :

* `/predict` ‚Äì pr√©diction √† partir d‚Äôun payload JSON
* `/metadata` ‚Äì informations sur le projet et le mod√®le
* `/models` ‚Äì mod√®les disponibles et mod√®le par d√©faut
* `/metrics` ‚Äì m√©triques de performance

La documentation interactive est disponible via **Swagger/OpenAPI**.

---

## üóÑÔ∏è Base de donn√©es

* **SGBD** : PostgreSQL
* **H√©bergement** : Neon (serverless)
* **ORM** : SQLAlchemy

Toutes les interactions avec le mod√®le passent par la base :

* donn√©es d‚Äôentr√©e (inputs)
* r√©sultats de pr√©diction (outputs)

Cela garantit la **tra√ßabilit√© compl√®te** des √©changes.

---

## üß™ Tests & Qualit√©

* Tests unitaires et fonctionnels avec **Pytest**
* Couverture de code via **pytest‚Äëcov**
* Ex√©cution automatique dans **GitHub Actions**

---

## üîÑ CI/CD

* Lint + tests sur chaque PR (`main`, `dev`)
* D√©ploiement automatique sur Hugging Face Spaces apr√®s validation

## Reproductibilit√©
* Fixer seeds dans exp√©rimentations
* Versionner les mod√®les (nom + date + hash)
* Utiliser artefacts externes (S3 / HF Hub) pour stocker les mod√®les

## Branching & Commit
* Conventional Commits
* Branches: `feature/`, `bugfix/`, `hotfix/`, `release/`
* PR mandatory, 1 reviewer minimum

---

## üìä Dashboard

Un dashboard Streamlit permet :

* la consultation des m√©triques
* la comparaison des mod√®les
* l‚Äôhistorique des pr√©dictions

---

## üìö Documentation

La documentation d√©taill√©e est disponible dans le dossier `docs/`.

---

## Pr√©requis
* Python 3.10 ‚Äî 3.12 (recommand√© : 3.10 ou 3.12 selon ton environnement)
* Git
* Node.js + npm (pour `commitlint`)
* PostgreSQL
* Compte GitHub (pour CI / Actions) et acc√®s Hugging Face si tu d√©ploies sur HF Spaces

---

## Conventions & Outils qualit√©
* Style : PEP8  
* Formatage : `black`  
* Imports : `isort` (profil `black`)  
* Linter : `flake8`  
* Hooks : `pre-commit` (configuration locale par d√©faut, voir `.pre-commit-config.yaml`)  
* Commit messages : Conventional Commits (valid√©s par `commitlint` au stade `commit-msg`)

---
## Installation (local)
git clone git@github.com:TON_COMPTE/futurisys-ml-deploy.git
cd futurisys-ml-deploy

**Python (venv)**
python -m venv .venv
source .venv/bin/activate

**installer runtime + dev tools**
pip install -r api/requirements.txt
pip install -r dashboard/requirements.txt
pip install -r requirements-dev.txt

---
**Installer commitlint dans le projet (recommand√©) si le repo n'a pas package.json**
npm init -y
npm install --save-dev @commitlint/cli @commitlint/config-conventional
***config minimale***
echo "module.exports = { extends: ['@commitlint/config-conventional'] };" > commitlint.config.js

***si tu utilises pip / venv / conda***
pip install "black==23.1.0" "isort==5.12.0" "flake8==6.0.0"

## ***Nettoyer cache pre-commit et r√©installer hooks***
rm -rf ~/.cache/pre-commit
pre-commit clean
pre-commit install

## ***Tester les hooks (fichiers)***
pre-commit run --all-files -v


## **Tester le hook commit-msg (2 fa√ßons)**
**M√©thode A ‚Äî faire un vrai commit (recommand√©e)**
git commit --allow-empty -m "feat: test commit-msg (should pass)"
***puis pour un message invalide***
git commit --allow-empty -m "invalid message"

**M√©thode B ‚Äî test manuel avec un fichier message**
echo "invalid message" > .git/COMMIT_EDITMSG
pre-commit run --hook-stage commit-msg -v --commit-msg-filename .git/COMMIT_EDITMSG

---

## üõ†Ô∏è Installation (local)

pip install -r requirements.txt
export DATABASE_URL="postgresql+psycopg://..."
uvicorn src.api.main:app --reload

---
## Tests
* Tests unitaires avec `pytest`
* Tests rapides dans CI (pas d'entra√Ænement)
* Pour tests d'int√©gration lourds, utiliser une pipeline s√©par√©e / runners self-hosted

***Commande pour ex√©cuter les tests :***
* Tests unitaires ML
pytest tests/unit/test_predictor.py

* Tests de sch√©mas
pytest tests/schemas/test_schemas_input.py

* Tests fonctionnels API
pytest tests/functional/test_functional_model.py

***Commande pour g√©n√©rer un rapport de couverture :***
pytest --cov=src --cov-report=xml

***Test avec couverture de code***
pytest --cov=src --cov-report=term-missing
pytest --cov=src --cov-report=html

***D√©marrer l‚ÄôAPI localement***
Avec Uvicorn (recommand√© en dev) : 
uvicorn src.api.main:app --reload
L‚ÄôAPI est disponible sur :
Swagger UI : http://127.0.0.1:8000/docs
