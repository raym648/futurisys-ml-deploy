# Tests unitaires, de schÃ©mas et fonctionnels

## ğŸ¯ Objectif

Cette documentation dÃ©crit **exclusivement la stratÃ©gie de tests unitaires, de validation des schÃ©mas et de tests fonctionnels**
du projet *Futurisys ML Deploy*. Elle explique **ce qui est testÃ©, comment, et pourquoi**,
sans couvrir lâ€™architecture globale ni le monitoring.

Lâ€™objectif est de garantir :

* la fiabilitÃ© de la logique ML,
* la robustesse de la validation des donnÃ©es,
* le bon fonctionnement de lâ€™API exposÃ©e.

---

## ğŸ§ª Tests unitaires (logique ML)

Les tests unitaires valident chaque composant de maniÃ¨re **isolÃ©e**,
sans dÃ©pendance externe (API FastAPI, base de donnÃ©es, artefacts lourds).

### ğŸ¯ Cibles principales

* `src/ml/predictor.py`
* `src/ml/model_registry.py`
* Fonctions utilitaires ML (prÃ©paration des features, sÃ©lection de modÃ¨le)

### âš™ï¸ Principes clÃ©s

* **Isolation complÃ¨te de la logique mÃ©tier ML**
* Chargement **lazy** des modÃ¨les
* Aucun serveur API requis
* Aucun accÃ¨s disque obligatoire

### ğŸ“Œ Cas testÃ©s

* SÃ©lection du modÃ¨le par dÃ©faut
* SÃ©lection explicite dâ€™un modÃ¨le valide
* Rejet dâ€™un modÃ¨le inconnu
* Reconstruction correcte du vecteur de features
* GÃ©nÃ©ration dâ€™une prÃ©diction valide
* Gestion contrÃ´lÃ©e des erreurs ML

### ğŸ“„ Fichiers concernÃ©s

* `tests/unit/test_predictor.py`

---

## ğŸ“ Tests de schÃ©mas (validation des donnÃ©es)

Les tests de schÃ©mas vÃ©rifient la **validation stricte des entrÃ©es utilisateur**
via Pydantic, indÃ©pendamment de lâ€™API et du modÃ¨le ML.

### ğŸ¯ Cibles principales

* SchÃ©mas Pydantic (`PredictionInput`, Enums)
* Contraintes de types et de valeurs

### âš™ï¸ Principes clÃ©s

* Validation exÃ©cutÃ©e **avant toute logique mÃ©tier**
* Rejet automatique des donnÃ©es invalides (`HTTP 422`)
* Source de vÃ©ritÃ© alignÃ©e avec le dataset `.csv`

### ğŸ“Œ Cas testÃ©s

* Payload valide
* Valeur Enum invalide
* Champ manquant
* Type incorrect

### ğŸ“„ Fichiers concernÃ©s

* `tests/schemas/test_schemas_input.py`

---

## ğŸŒ Tests fonctionnels (API FastAPI)

Les tests fonctionnels valident le **comportement global de lâ€™application**
via lâ€™API FastAPI, en simulant un usage rÃ©el.

### ğŸ¯ Cibles principales

* Endpoints FastAPI
* IntÃ©gration API â†” couche ML
* Gestion des erreurs HTTP

### âš™ï¸ Principes clÃ©s

* Utilisation de `fastapi.testclient.TestClient`
* Base de donnÃ©es neutralisÃ©e via mocks
* Aucun modÃ¨le rÃ©el requis

### ğŸ”„ Flux testÃ©

1. Appel de lâ€™endpoint `/predict`
2. Validation du payload (Pydantic)
3. Appel de la couche ML (`predictor`)
4. GÃ©nÃ©ration de la prÃ©diction
5. RÃ©ponse API structurÃ©e

### ğŸ“Œ Cas testÃ©s

* PrÃ©diction nominale via API
* ModÃ¨le invalide (erreur contrÃ´lÃ©e)
* Format de rÃ©ponse conforme au contrat API
* Robustesse face Ã  un payload invalide

### ğŸ“„ Fichiers concernÃ©s

* `tests/functional/test_functional_model.py`

---

## ğŸ¤– IntÃ©gration CI (GitHub Actions)

Les tests sont exÃ©cutÃ©s automatiquement et **sÃ©parÃ©ment** dans la pipeline CI.

### Ã‰tapes CI

* Tests unitaires ML
* Tests de schÃ©mas Pydantic
* Tests fonctionnels API
* Rapport de couverture de code
* Smoke tests FastAPI

### SpÃ©cificitÃ©s CI

* `ENV=test` activÃ©
* Artefacts ML mockÃ©s
* Aucune dÃ©pendance externe requise

---

## âœ… BÃ©nÃ©fices

* SÃ©paration claire des responsabilitÃ©s
* DÃ©tection prÃ©coce des rÃ©gressions
* Validation stricte du contrat API
* Pipeline CI fiable et reproductible

---

## ğŸ“Œ Conclusion

La stratÃ©gie de tests garantit que :

* la logique ML est fiable et testÃ©e isolÃ©ment,
* les donnÃ©es dâ€™entrÃ©e sont strictement validÃ©es,
* lâ€™API se comporte correctement en conditions rÃ©elles,
* chaque couche peut Ã©voluer indÃ©pendamment.

Cette approche est conforme aux **bonnes pratiques MLOps et API ML en production**.
