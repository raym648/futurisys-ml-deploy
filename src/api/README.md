---
title: Futurisys API
emoji: ğŸš€
colorFrom: red
colorTo: red
sdk: docker
app_port: 7860
tags:
  - machine-learning
  - fastapi
  - docker
  - ml-deployment
pinned: false
short_description: API FastAPI pour dÃ©ployer un modÃ¨le de Machine Learning
---

# ğŸš€ Futurisys API â€“ ML Deployment

**Futurisys API** est une API **FastAPI** permettant dâ€™exposer un modÃ¨le de **Machine Learning** entraÃ®nÃ© et sÃ©rialisÃ© (`.joblib`).  
Ce projet sâ€™inscrit dans le cadre du **Projet 5 â€“ DÃ©ployez un modÃ¨le de Machine Learning**.

Lâ€™API est conÃ§ue pour Ãªtre :
- âœ… exÃ©cutÃ©e dans un **conteneur Docker**
- âœ… dÃ©ployÃ©e sur **Hugging Face Spaces (Docker SDK)**
- âœ… consommÃ©e par des applications externes (front, Streamlit, etc.)

---

## ğŸ§  FonctionnalitÃ©s

- Chargement dâ€™un modÃ¨le ML (`joblib`)
- Endpoint(s) de prÃ©diction
- API REST exposÃ©e via **FastAPI**
- Documentation automatique
- DÃ©ploiement simple via Docker

---

## ğŸ³ DÃ©ploiement (Docker / Hugging Face Space)

Cette application utilise le **SDK Docker** de Hugging Face.

### ğŸ”¹ Port exposÃ©
Lâ€™API Ã©coute sur le port :

```text
7860
```

---

## DÃ©marrage local

1. ***CrÃ©er et activer un environnement Python (3.10+)***
```bash
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

2. ***Placer le modÃ¨le sous models/model.joblib (ou adapter MODEL_PATH dans app/main.py).***

3. ***Lancer l'API:***
```bash
uvicorn app.main:app --reload --port 8000
```

4. ***Docs automatiques:***
Swagger UI: http://localhost:8000/docs
ReDoc: http://localhost:8000/redoc
